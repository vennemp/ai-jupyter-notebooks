{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this lab you must have:\n",
    "1. an OpenAI API Key.  To get one you can use free tier for limited use, https://platform.openai.com/.\n",
    "2. Python and pip installed on your machine. Select the proper version (kernel) at top right of this notebook.\n",
    "\n",
    "I tried to run this using Bedrock but unfortunately Bedrock has a hard token limit of 8000 per request and since was quite larger - 300k which even it was feasible would have been about $5 per request.  A token is about 4 characters of text.  \n",
    "\n",
    "Comment out the line for your operating system and enter the api key and click run (Play button at left of code block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env OPENAI_API_KEY=xxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain openai\n",
    "##if prompted to install ipynb plugin accept - it is required to run jupyter notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to initialize your OpenAI client.  Temperature is a standard LLM parameter that controls the randomness of the response - the lower the value the less random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.tools import AIPluginTool\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will ask OpenAI a question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke('What tshirts are available from Klarna in the US')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the response claims that it does not know anything about what products Klarna provides.  That is because this information is not trained into ChatGPT.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = AIPluginTool.from_plugin_url(\"https://www.klarna.com/.well-known/ai-plugin.json\")\n",
    "tools = load_tools([\"requests_all\"])\n",
    "tools += [tool]\n",
    "\n",
    "agent_chain = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads and initializes the plugin defined at the url above.   [It also loads the requests_all built-in tool](https://python.langchain.com/docs/integrations/tools/requests) - which is used to access websites for information.\n",
    "\n",
    "This contents are as follows.\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"schema_version\": \"v1\",\n",
    "  \"name_for_model\": \"KlarnaProducts\",\n",
    "  \"name_for_human\": \"Klarna Shopping\",\n",
    "  \"description_for_human\": \"Search and compare prices from thousands of online shops. Only available in the US.\",\n",
    "  \"description_for_model\": \"Assistant uses the Klarna plugin to get relevant product suggestions for any shopping or product discovery purpose. Assistant will reply with the following 3 paragraphs 1) Search Results 2) Product Comparison of the Search Results 3) Followup Questions. The first paragraph contains a list of the products with their attributes listed clearly and concisely as bullet points under the product, together with a link to the product and an explanation. Links will always be returned and should be shown to the user. The second paragraph compares the results returned in a summary sentence starting with \\\"In summary\\\". Assistant comparisons consider only the most important features of the products that will help them fit the users request, and each product mention is brief, short and concise. In the third paragraph assistant always asks helpful follow-up questions and end with a question mark. When assistant is asking a follow-up question, it uses it's product expertise to provide information pertaining to the subject of the user's request that may guide them in their search for the right product.\",\n",
    "  \"api\": {\n",
    "    \"type\": \"openapi\",\n",
    "    \"url\": \"https://www.klarna.com/us/shopping/public/openai/v0/api-docs/\",\n",
    "    \"has_user_authentication\": false\n",
    "  },\n",
    "  \"auth\": {\n",
    "    \"type\": \"none\"\n",
    "  },\n",
    "  \"logo_url\": \"https://www.klarna.com/assets/sites/5/2020/04/27143923/klarna-K-150x150.jpg\",\n",
    "  \"contact_email\": \"openai-products@klarna.com\",\n",
    "  \"legal_info_url\": \"https://www.klarna.com/us/legal/\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run(\"what t shirts are available in klarna in the US?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This outputs the entire chain of thought introduced by the Plugin this is helpful to decipher what the LLM is doing - this is a feature of using of agents.  We will explore agents more in depth in another lab.  \n",
    "\n",
    "Take notice of the url in the api.url field in the json  > https://www.klarna.com/us/shopping/public/openai/v0/api-docs.  This is the actual API documentation for the AI to browse.  The AI parses the description_for_model field in the json - this is where the LLM uses Natural Language Processing to comprehend the description of the API so it can understand why to use it. Notice the description is the first half of the observation - the second half is the actual API schema for the LLM to use.  \n",
    "\n",
    "The actual appears to have some sort of layer-4 or layer-7 filter so browsing the API endpoints directly does not work.\n",
    "\n",
    "```\n",
    "Observation: Usage Guide: Assistant uses the Klarna plugin to get relevant product suggestions for any shopping or product discovery purpose. Assistant will reply with the following 3 paragraphs 1) Search Results 2) Product Comparison of the Search Results 3) Followup Questions. The first paragraph contains a list of the products with their attributes listed clearly and concisely as bullet points under the product, together with a link to the product and an explanation. Links will always be returned and should be shown to the user. The second paragraph compares the results returned in a summary sentence starting with \"In summary\". Assistant comparisons consider only the most important features of the products that will help them fit the users request, and each product mention is brief, short and concise. In the third paragraph assistant always asks helpful follow-up questions and end with a question mark. When assistant is asking a follow-up question, it uses it's product expertise to provide information pertaining to the subject of the user's request that may guide them in their search for the right product.\n",
    "\n",
    "OpenAPI Spec: {'openapi': '3.0.1', 'info': {'version': 'v0', 'title': 'Open AI Klarna product Api'}, 'servers': [{'url': 'https://www.klarna.com/us/shopping'}], 'tags': [{'name': 'open-ai-product-endpoint', 'description': 'Open AI Product Endpoint. Query for products.'}], 'paths': {'/public/openai/v0/products': {'get': {'tags': ['open-ai-product-endpoint'], 'summary': 'API for fetching Klarna product information', 'operationId': 'productsUsingGET', 'parameters': [{'name': 'countryCode', 'in': 'query', 'description': 'ISO 3166 country code with 2 characters based on the user location. Currently, only US, GB, DE, SE and DK are supported.', 'required': True, 'schema': {'type': 'string'}}, {'name': 'q', 'in': 'query', 'description': \"A precise query that matches one very small category or product that needs to be searched for to find the products the user is looking for. If the user explicitly stated what they want, use that as a query. The query is as specific as possible to the product name or category mentioned by the user in its singular form, and don't contain any clarifiers like latest, newest, cheapest, budget, premium, expensive or similar. The query is always taken from the latest topic, if there is a new topic a new query is started. If the user speaks another language than English, translate their request into English (example: translate fia med knuff to ludo board game)!\", 'required': True, 'schema': {'type': 'string'}}, {'name': 'size', 'in': 'query', 'description': 'number of products returned', 'required': False, 'schema': {'type': 'integer'}}, {'name': 'min_price', 'in': 'query', 'description': \"(Optional) Minimum price in local currency for the product searched for. Either explicitly stated by the user or implicitly inferred from a combination of the user's request and the kind of product searched for.\", 'required': False, 'schema': {'type': 'integer'}}, {'name': 'max_price', 'in': 'query', 'description': \"(Optional) Maximum price in local currency for the product searched for. Either explicitly stated by the user or implicitly inferred from a combination of the user's request and the kind of product searched for.\", 'required': False, 'schema': {'type': 'integer'}}], 'responses': {'200': {'description': 'Products found', 'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ProductResponse'}}}}, '503': {'description': 'one or more services are unavailable'}}, 'deprecated': False}}}, 'components': {'schemas': {'Product': {'type': 'object', 'properties': {'attributes': {'type': 'array', 'items': {'type': 'string'}}, 'name': {'type': 'string'}, 'price': {'type': 'string'}, 'url': {'type': 'string'}}, 'title': 'Product'}, 'ProductResponse': {'type': 'object', 'properties': {'products': {'type': 'array', 'items': {'$ref': '#/components/schemas/Product'}}}, 'title': 'ProductResponse'}}}}\n",
    "```\n",
    "\n",
    "It then parses the descriptions of the api methods defined in the schema to understand what each API method should be used for.  The description of the parameters in the schema give the LLM context on how to build the API request.\n",
    "\n",
    "Notice in the next Thought it shows that it understands how to use the API. It then establishes an Action and Action input based on the api schema and the tool definition and then it executes the action.\n",
    "Thought:I can use the Klarna Shopping API to search for t-shirts in the US by making a GET request to the /public/openai/v0/products endpoint with the appropriate parameters.\n",
    "Action: requests_get\n",
    "Action Input: \"https://www.klarna.com/us/shopping/public/openai/v0/products?countryCode=US&q=t-shirts\"\n",
    "\n",
    "The next Observation is the json response of the GET request.\n",
    "It processes this information and then remembers the original query - \"what tshirts are available in klarna in the US?\" and uses the json to craft a natural language response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see Langchain agents enable you to feed data dynamically to your LLM to improve it's awareness.  Tools can be used to invoke API calls, run abitrary shell or python scripts, invoke Lambda functions and more.  Plugin's context and information that the tools can use - in this case the API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
