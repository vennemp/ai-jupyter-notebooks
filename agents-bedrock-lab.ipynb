{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to explore running agents with Amazon Bedrock.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "import boto3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This requires you to have a named profile configured in your ~/.aws/config or ~/.aws/credentials file.  This supports AWS IC if you have that configured with your CLI.  Just pass it the profile name you use after successfully authenticating with \n",
    "\n",
    "```bash\n",
    "aws sso login --profile <profile name>\n",
    "```\n",
    "Note: this can be run from anywhere on your computer not necessarily the same terminal session.\n",
    "\n",
    "Enter the name of the profile line 2 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION_NAME=\"us-east-1\" ## change to your region\n",
    "PROFILE_NAME=\"lza-comm-gss\"  ## change to your desired aws credential profile\n",
    "## ensure AI21 Jurassic Ultra is enabled in your AWS Account.\n",
    "named_profile = boto3.session.Session(profile_name=PROFILE_NAME)\n",
    "bedrock_client = named_profile.client('bedrock-runtime')\n",
    "print('Initalizing Bedrock AI21 Jurassic Ultra')\n",
    "llm = Bedrock(\n",
    "    client=bedrock_client,\n",
    "    model_id=\"ai21.j2-ultra-v1\",\n",
    "    endpoint_url=\"https://bedrock-runtime.\" + REGION_NAME + \".amazonaws.com\",\n",
    "    model_kwargs={\"temperature\": 0.2, \"maxTokens\": 1200, \"numResults\": 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(\"What is the product of 4 and 28?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above command may stumble upon the correct answer 112 - but running it several times will show that it is rather inconsistent.  LLMs do not perform well with Math on their own. \n",
    "\n",
    "What we need to do is build in logic for the LLM to multiply two numbers together.  This is where tools come in...  \n",
    "\n",
    "We can define them with a decorator function.\n",
    "\n",
    "And then we add them to an array tools, where we can store multiple tools for our use to pass to our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers. Find the product of two numbers a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "tools=[multiply]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the agent and bind it to with the tools and our bedrock FM.  \n",
    "\n",
    "Notice that we use the STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION AgentType - this is because our tool requires multiple arguments - the two numbers to multiply.\n",
    "\n",
    "We pass the verbose argument so we can see a clear Chain of Thought.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"multiply\",\n",
      "  \"action_input\": {\n",
      "    \"a\": 94,\n",
      "    \"b\": 28\n",
      "  }\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m2632\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "Final response to human: 2632\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nFinal response to human: 2632'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What is the product of 94 and 28?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOOM!\n",
    "\n",
    "### Further reading:\n",
    "\n",
    "[Zero Shot vs Few Shot Prompting](https://machinelearningmastery.com/what-are-zero-shot-prompting-and-few-shot-prompting/)\n",
    "\n",
    "[ReAct: Reasoning + Action](https://arxiv.org/abs/2210.03629)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
